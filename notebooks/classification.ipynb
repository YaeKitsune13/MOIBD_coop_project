{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e052bf",
   "metadata": {},
   "source": [
    "### МОДЕЛИ КЛАССИФИКАЦИИ ДЛЯ ПРОГНОЗИРОВАНИЯ ОТКЛИКА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f582111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек для классификации\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, confusion_matrix, classification_report,\n",
    "                             roc_curve, precision_recall_curve)\n",
    "import joblib\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ef1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/marketing_campaign.csv', sep='\\t')\n",
    "\n",
    "# Нормализация категорий\n",
    "df[\"Education\"] = df[\"Education\"].replace({\"2n Cycle\": \"Pre-Graduate\", \"Basic\": \"Pre-Graduate\"})\n",
    "df[\"Marital_Status\"] = df[\"Marital_Status\"].replace({\n",
    "    \"Married\": \"Married/Together\", \"Together\": \"Married/Together\",\n",
    "    \"Single\": \"Single\", \"Divorced\": \"Other\", \"Widow\": \"Other\",\n",
    "    \"Alone\": \"Other\", \"Absurd\": \"Other\", \"YOLO\": \"Other\"\n",
    "})\n",
    "\n",
    "# Feature engineering\n",
    "df[\"Kids\"] = df[\"Kidhome\"].astype(\"int8\") + df[\"Teenhome\"].astype(\"int8\")\n",
    "df[\"Expenses\"] = df[[\"MntWines\", \"MntFruits\", \"MntMeatProducts\", \"MntFishProducts\", \"MntSweetProducts\", \"MntGoldProds\"]].sum(axis=1)\n",
    "df[\"TotalAcceptedCmp\"] = df[[\"AcceptedCmp1\", \"AcceptedCmp2\", \"AcceptedCmp3\", \"AcceptedCmp4\", \"AcceptedCmp5\"]].astype(\"int8\").sum(axis=1)\n",
    "df[\"TotalNumPurchases\"] = df[[\"NumWebPurchases\", \"NumCatalogPurchases\", \"NumStorePurchases\", \"NumDealsPurchases\"]].sum(axis=1)\n",
    "\n",
    "# Удаление лишних колонок\n",
    "df.drop(columns=[\"Kidhome\", \"Teenhome\", \"MntWines\", \"MntFruits\", \"MntMeatProducts\", \"MntFishProducts\", \n",
    "                \"MntSweetProducts\", \"MntGoldProds\", \"AcceptedCmp1\", \"AcceptedCmp2\", \"AcceptedCmp3\", \n",
    "                \"AcceptedCmp4\", \"AcceptedCmp5\", \"NumWebPurchases\", \"NumCatalogPurchases\", \n",
    "                \"NumStorePurchases\", \"NumDealsPurchases\"], inplace=True)\n",
    "\n",
    "df[\"Kids\"] = df[\"Kids\"].replace({0: \"No Kid\", 1: \"Has Kids\", 2: \"Has Kids\", 3: \"Has Kids\"})\n",
    "df[\"TotalAcceptedCmp\"] = df[\"TotalAcceptedCmp\"].replace({0: \"0\", 1: \">0\", 2: \">0\", 3: \">0\", 4: \">0\"})\n",
    "\n",
    "num_features = [\"Income\", \"Recency\", \"NumWebVisitsMonth\", \"Expenses\", \"TotalNumPurchases\"]\n",
    "cat_features = [\"Education\", \"Marital_Status\", \"Response\", \"Complain\", \"Kids\", \"TotalAcceptedCmp\"]\n",
    "\n",
    "# Очистка Income\n",
    "df['Income'] = df['Income'].fillna(df['Income'].median())\n",
    "df = df[df['Income'] < 600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем признаки для модели\n",
    "# Числовые признаки \n",
    "numeric_features = [\"Income\", \"Recency\", \"NumWebVisitsMonth\", \"Expenses\", \"TotalNumPurchases\"]\n",
    "\n",
    "# Категориальные признаки \n",
    "categorical_features = [\"Education\", \"Marital_Status\", \"Complain\", \"Kids\", \"TotalAcceptedCmp\"]\n",
    "\n",
    "# Выбираем все признаки для модели\n",
    "feature_cols = numeric_features + categorical_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3139091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем матрицу признаков и целевую переменную\n",
    "X = df[feature_cols].copy()\n",
    "y = df['Response'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6734cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация дисбаланса классов\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Pie chart\n",
    "axes[0].pie(y.value_counts(), labels=['Нет отклика (0)', 'Отклик (1)'], \n",
    "            autopct='%1.1f%%', colors=['#ff9999', '#66b3ff'], startangle=90)\n",
    "axes[0].set_title('Распределение целевой переменной', fontsize=14)\n",
    "# Bar chart\n",
    "axes[1].bar(['Нет отклика (0)', 'Отклик (1)'], y.value_counts(), \n",
    "            color=['#ff9999', '#66b3ff'], edgecolor='black')\n",
    "axes[1].set_title('Количество наблюдений по классам', fontsize=14)\n",
    "axes[1].set_ylabel('Количество')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eabd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для классификации\n",
    "# Целевая переменная - Response (отклик на последнюю кампанию)\n",
    "print(\"Распределение целевой переменной:\")\n",
    "print(df['Response'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6862118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем препроцессор для обработки разных типов данных\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Обучаем препроцессор на тренировочных данных\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Получаем названия признаков после обработки\n",
    "# Для числовых - оставляем оригинальные названия\n",
    "num_feature_names = numeric_features\n",
    "\n",
    "# Для категориальных - получаем названия после one-hot\n",
    "cat_feature_names = []\n",
    "for cat_feat in categorical_features:\n",
    "    categories = preprocessor.named_transformers_['cat'].categories_[categorical_features.index(cat_feat)]\n",
    "    for cat in categories:\n",
    "        cat_feature_names.append(f\"{cat_feat}_{cat}\")\n",
    "        \n",
    "all_feature_names = num_feature_names + cat_feature_names\n",
    "\n",
    "print(f\"Всего признаков после обработки: {len(all_feature_names)}\")\n",
    "\n",
    "# Сохраняем препроцессор\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294cd07a",
   "metadata": {},
   "source": [
    "### МЕТОД 1: ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логистическая регрессия с подбором гиперпараметров\n",
    "log_reg_params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Grid Search с кросс-валидацией\n",
    "log_reg_grid = GridSearchCV(\n",
    "    log_reg, \n",
    "    log_reg_params, \n",
    "    cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "log_reg_grid.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры для логистической регрессии:\")\n",
    "print(log_reg_grid.best_params_)\n",
    "print(f\"Лучший ROC-AUC на кросс-валидации: {log_reg_grid.best_score_:.4f}\")\n",
    "\n",
    "# Лучшая модель\n",
    "best_log_reg = log_reg_grid.best_estimator_\n",
    "\n",
    "# Предсказания\n",
    "y_pred_log_reg = best_log_reg.predict(X_test_processed)\n",
    "y_pred_proba_log_reg = best_log_reg.predict_proba(X_test_processed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87987fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Метрики для логистической регрессии\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"МЕТРИКИ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "log_reg_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_log_reg),\n",
    "    'Precision': precision_score(y_test, y_pred_log_reg),\n",
    "    'Recall': recall_score(y_test, y_pred_log_reg),\n",
    "    'F1-Score': f1_score(y_test, y_pred_log_reg),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_pred_proba_log_reg)\n",
    "}\n",
    "\n",
    "for metric, value in log_reg_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_log_reg, target_names=['Нет отклика', 'Отклик']))\n",
    "\n",
    "# Матрица ошибок\n",
    "cm_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_log_reg, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Нет отклика', 'Отклик'],\n",
    "            yticklabels=['Нет отклика', 'Отклик'])\n",
    "plt.title('Матрица ошибок - Логистическая регрессия', fontsize=14)\n",
    "plt.ylabel('Фактическое значение')\n",
    "plt.xlabel('Предсказанное значение')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d1aeea",
   "metadata": {},
   "source": [
    "### МЕТОД 2: СЛУЧАЙНЫЙ ЛЕС (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7f85e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest с подбором гиперпараметров\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Grid Search с кросс-валидацией\n",
    "rf_grid = GridSearchCV(\n",
    "    rf, \n",
    "    rf_params, \n",
    "    cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры для Random Forest:\")\n",
    "print(rf_grid.best_params_)\n",
    "print(f\"Лучший ROC-AUC на кросс-валидации: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Лучшая модель\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "# Предсказания\n",
    "y_pred_rf = best_rf.predict(X_test_processed)\n",
    "y_pred_proba_rf = best_rf.predict_proba(X_test_processed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6158a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики для Random Forest\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"МЕТРИКИ RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rf_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'Precision': precision_score(y_test, y_pred_rf),\n",
    "    'Recall': recall_score(y_test, y_pred_rf),\n",
    "    'F1-Score': f1_score(y_test, y_pred_rf),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_pred_proba_rf)\n",
    "}\n",
    "\n",
    "for metric, value in rf_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Нет отклика', 'Отклик']))\n",
    "\n",
    "# Матрица ошибок\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['Нет отклика', 'Отклик'],\n",
    "            yticklabels=['Нет отклика', 'Отклик'])\n",
    "plt.title('Матрица ошибок - Random Forest', fontsize=14)\n",
    "plt.ylabel('Фактическое значение')\n",
    "plt.xlabel('Предсказанное значение')\n",
    "plt.show()\n",
    "\n",
    "# Важность признаков (для Random Forest)\n",
    "if hasattr(best_rf, 'feature_importances_'):\n",
    "    # Получаем важность признаков\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': all_feature_names,\n",
    "        'importance': best_rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=feature_importance.head(5), x='importance', y='feature', palette='viridis')\n",
    "    plt.title('Топ-5 наиболее важных признаков (Random Forest)', fontsize=14)\n",
    "    plt.xlabel('Важность')\n",
    "    plt.ylabel('Признак')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c12884c",
   "metadata": {},
   "source": [
    "### МЕТОД 3: GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd11cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting с подбором гиперпараметров\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Grid Search с кросс-валидацией\n",
    "gb_grid = GridSearchCV(\n",
    "    gb, \n",
    "    gb_params, \n",
    "    cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры для Gradient Boosting:\")\n",
    "print(gb_grid.best_params_)\n",
    "print(f\"Лучший ROC-AUC на кросс-валидации: {gb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Лучшая модель\n",
    "best_gb = gb_grid.best_estimator_\n",
    "\n",
    "# Предсказания\n",
    "y_pred_gb = best_gb.predict(X_test_processed)\n",
    "y_pred_proba_gb = best_gb.predict_proba(X_test_processed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики для Gradient Boosting\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"МЕТРИКИ GRADIENT BOOSTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gb_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_gb),\n",
    "    'Precision': precision_score(y_test, y_pred_gb),\n",
    "    'Recall': recall_score(y_test, y_pred_gb),\n",
    "    'F1-Score': f1_score(y_test, y_pred_gb),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_pred_proba_gb)\n",
    "}\n",
    "\n",
    "for metric, value in gb_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb, target_names=['Нет отклика', 'Отклик']))\n",
    "\n",
    "# Матрица ошибок\n",
    "cm_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_gb, annot=True, fmt='d', cmap='Oranges', \n",
    "            xticklabels=['Нет отклика', 'Отклик'],\n",
    "            yticklabels=['Нет отклика', 'Отклик'])\n",
    "plt.title('Матрица ошибок - Gradient Boosting', fontsize=14)\n",
    "plt.ylabel('Фактическое значение')\n",
    "plt.xlabel('Предсказанное значение')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2206e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение метрик всех моделей\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Логистическая регрессия': log_reg_metrics,\n",
    "    'Random Forest': rf_metrics,\n",
    "    'Gradient Boosting': gb_metrics\n",
    "}).T\n",
    "\n",
    "print(\"СРАВНЕНИЕ МОДЕЛЕЙ:\")\n",
    "print(models_comparison.round(4))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "metrics_names = list(log_reg_metrics.keys())\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "for idx, metric in enumerate(metrics_names):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    values = [log_reg_metrics[metric], rf_metrics[metric], gb_metrics[metric]]\n",
    "    bars = axes[row, col].bar(['Log Reg', 'Random Forest', 'Gradient Boost'], values, color=colors, edgecolor='black')\n",
    "    axes[row, col].set_title(f'Сравнение: {metric}', fontsize=12)\n",
    "    axes[row, col].set_ylim([0, 1])\n",
    "    axes[row, col].set_ylabel('Значение')\n",
    "    \n",
    "    for bar, value in zip(bars, values):\n",
    "        axes[row, col].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                           f'{value:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.suptitle('Сравнение метрик моделей классификации', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ROC-кривые для всех моделей\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "fpr_log, tpr_log, _ = roc_curve(y_test, y_pred_proba_log_reg)\n",
    "plt.plot(fpr_log, tpr_log, label=f'Logistic Regression (AUC = {log_reg_metrics[\"ROC-AUC\"]:.3f})', \n",
    "         linewidth=2, color='#FF6B6B')\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_metrics[\"ROC-AUC\"]:.3f})', \n",
    "         linewidth=2, color='#4ECDC4')\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y_test, y_pred_proba_gb)\n",
    "plt.plot(fpr_gb, tpr_gb, label=f'Gradient Boosting (AUC = {gb_metrics[\"ROC-AUC\"]:.3f})', \n",
    "         linewidth=2, color='#45B7D1')\n",
    "\n",
    "# Диагональная линия\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC-кривые моделей классификации', fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d42ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ce14136",
   "metadata": {},
   "source": [
    "### СОХРАНЕНИЕ ЛУЧШЕЙ МОДЕЛИ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa668c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем лучшую модель по F1-score\n",
    "model_scores = {\n",
    "    'Logistic Regression': log_reg_metrics['F1-Score'],\n",
    "    'Random Forest': rf_metrics['F1-Score'],\n",
    "    'Gradient Boosting': gb_metrics['F1-Score']\n",
    "}\n",
    "\n",
    "best_model_name = max(model_scores, key=model_scores.get)\n",
    "best_model_score = model_scores[best_model_name]\n",
    "\n",
    "print(f\"Лучшая модель: {best_model_name}\")\n",
    "print(f\"F1-Score: {best_model_score:.4f}\")\n",
    "\n",
    "# Сохраняем лучшую модель\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    best_model = best_log_reg\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = best_rf\n",
    "else:\n",
    "    best_model = best_gb\n",
    "\n",
    "# Сохраняем модель и препроцессор\n",
    "joblib.dump(best_model, 'best_model.joblib')\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "joblib.dump(all_feature_names, 'feature_names.pkl')\n",
    "\n",
    "print(\"\\nМодель сохранена как 'best_model.joblib'\")\n",
    "print(\"Препроцессор сохранен как 'preprocessor.pkl'\")\n",
    "print(\"Названия признаков сохранены в 'feature_names.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66206f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для загрузки и использования модели\n",
    "def load_and_predict(model_path, preprocessor_path, new_data):\n",
    "    \"\"\"\n",
    "    Функция для загрузки модели и предсказания на новых данных\n",
    "    \"\"\"\n",
    "    # Загружаем модель и препроцессор\n",
    "    model = joblib.load(model_path)\n",
    "    preprocessor = joblib.load(preprocessor_path)\n",
    "    \n",
    "    # Обрабатываем новые данные\n",
    "    new_data_processed = preprocessor.transform(new_data)\n",
    "    \n",
    "    # Делаем предсказания\n",
    "    predictions = model.predict(new_data_processed)\n",
    "    probabilities = model.predict_proba(new_data_processed)\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "print(\"\\nПример использования функции загрузки модели:\")\n",
    "print(\"predictions, probabilities = load_and_predict('best_model.joblib', 'preprocessor.pkl', new_data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dafe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример предсказания на тестовых данных\n",
    "sample_indices = np.random.choice(len(X_test), 5, replace=False)\n",
    "sample_data = X_test.iloc[sample_indices]\n",
    "sample_true = y_test.iloc[sample_indices]\n",
    "\n",
    "# Предсказания лучшей моделью\n",
    "sample_pred = best_model.predict(X_test_processed[sample_indices])\n",
    "sample_proba = best_model.predict_proba(X_test_processed[sample_indices])\n",
    "\n",
    "print(\"ПРИМЕР ПРЕДСКАЗАНИЙ НА ТЕСТОВЫХ ДАННЫХ:\")\n",
    "print(\"-\" * 80)\n",
    "for i in range(len(sample_indices)):\n",
    "    print(f\"Образец {i+1}:\")\n",
    "    print(f\"  Фактическое значение: {sample_true.iloc[i]}\")\n",
    "    print(f\"  Предсказанное значение: {sample_pred[i]}\")\n",
    "    print(f\"  Вероятность отклика: {sample_proba[i][1]:.4f}\")\n",
    "    print(f\"  Вероятность отсутствия отклика: {sample_proba[i][0]:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d10037",
   "metadata": {},
   "source": [
    "### ИТОГОВЫЕ ВЫВОДЫ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de48bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ИТОГОВЫЕ ВЫВОДЫ ПО МОДЕЛЯМ КЛАССИФИКАЦИИ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "На основе проведенного моделирования можно сделать следующие выводы:\n",
    "\n",
    "1. ЛУЧШАЯ МОДЕЛЬ: {best_model_name}\n",
    "   - F1-Score: {best_model_score:.4f}\n",
    "   - ROC-AUC: {model_scores[best_model_name]:.4f}\n",
    "\n",
    "2. КЛЮЧЕВЫЕ ФАКТОРЫ:\n",
    "   - Общие расходы клиента (Expenses)\n",
    "   - Доход (Income)\n",
    "   - Количество покупок (TotalNumPurchases)\n",
    "   - Наличие детей (Kids)\n",
    "   - История участия в кампаниях (TotalAcceptedCmp)\n",
    "\n",
    "3. РЕКОМЕНДАЦИИ:\n",
    "   - Фокусироваться на клиентах с высокими расходами\n",
    "   - Учитывать семейное положение и наличие детей\n",
    "   - Использовать историю предыдущих кампаний\n",
    "   - Применять кластеризацию для сегментации\n",
    "\n",
    "4. ПРАКТИЧЕСКОЕ ПРИМЕНЕНИЕ:\n",
    "   - Модель сохранена и готова к использованию\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be004d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сводная таблица\n",
    "summary_table = pd.DataFrame({\n",
    "    'Метод': ['Логистическая регрессия', 'Random Forest', 'Gradient Boosting'],\n",
    "    'Accuracy': [log_reg_metrics['Accuracy'], rf_metrics['Accuracy'], gb_metrics['Accuracy']],\n",
    "    'Precision': [log_reg_metrics['Precision'], rf_metrics['Precision'], gb_metrics['Precision']],\n",
    "    'Recall': [log_reg_metrics['Recall'], rf_metrics['Recall'], gb_metrics['Recall']],\n",
    "    'F1-Score': [log_reg_metrics['F1-Score'], rf_metrics['F1-Score'], gb_metrics['F1-Score']],\n",
    "    'ROC-AUC': [log_reg_metrics['ROC-AUC'], rf_metrics['ROC-AUC'], gb_metrics['ROC-AUC']]\n",
    "})\n",
    "\n",
    "print(\"\\nСВОДНАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ:\")\n",
    "print(summary_table.round(4).to_string(index=False))\n",
    "\n",
    "# Сохраняем результаты\n",
    "summary_table.to_csv('model_results.csv', index=False)\n",
    "print(\"\\nРезультаты сохранены в 'model_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecf40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
